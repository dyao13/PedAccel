{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b739ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================== #\n",
    "# pmap/share/ptsd.py -- shared routines for physiologic time series data\n",
    "#                 extraction\n",
    "#\n",
    "# History\n",
    "#  - 9/10/2020 created, jpb\n",
    "#  - 3/1/2022 reorganized into ptsd dir, split into util/saver, jpb\n",
    "#  - 3/15/2022 move internal routines to util_int.py, jpb\n",
    "#  - 9/15/2022 fix zarr_save_waveform for ZARR 2.11.0\n",
    "#      [1] clobber=True arg to normalize_store_arg replaced w/mode='w'\n",
    "#  - 10/31/2022 (Happy Halloween!) moved into pmap/share/ptsd.py\n",
    "# ===================================================================== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61833428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dateutil import tz\n",
    "\n",
    "import zarr\n",
    "import numcodecs\n",
    "from zarr.creation import normalize_store_arg, open_array\n",
    "from zarr.hierarchy import group as _create_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15922b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zarr_save_waveform(store, df):\n",
    "    may_need_closing = isinstance(store, str)\n",
    "    store = normalize_store_arg(store, mode='w')       # [1] for ZARR 2.11.0\n",
    "    # store = normalize_store_arg(store, clobber=True) # pre ZARR 2.11.0\n",
    "    \n",
    "    fmt = 'v2'\n",
    "    #if df.columns[0] == 'ts' and df.columns[1] == 'dt':\n",
    "    #    fmt = 'v1'\n",
    "\n",
    "    info = {'fmt': fmt}\n",
    "\n",
    "    if fmt == 'v1':\n",
    "        info['cols'] = df.columns.to_list()[2:]\n",
    "    elif fmt == 'v2':\n",
    "        info['cols'] = df.columns.to_list()\n",
    "    else:\n",
    "        assert False\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        grp = _create_group(store, overwrite=True)\n",
    "        \n",
    "        o = grp.empty('info', shape=1, overwrite=True, dtype='object',\n",
    "                      object_codec = numcodecs.JSON())\n",
    "        o[0] = info\n",
    "        if fmt == 'v1':\n",
    "            df_ts   = df.iloc[:, 0:2]\n",
    "            df_data = df.iloc[:, 2:]\n",
    "            grp.create_dataset('ts', data=df_ts.to_numpy(), overwrite=True)\n",
    "            grp.create_dataset('data', data=df_data.to_numpy(), overwrite=True)\n",
    "        elif fmt == 'v2':\n",
    "            grp.create_dataset('data_v2', data=df.to_numpy(), overwrite=True)\n",
    "        else:\n",
    "            assert False\n",
    "            \n",
    "    finally:\n",
    "        if may_need_closing and hasattr(store, 'close'):\n",
    "            # needed to ensure zip file records are written\n",
    "            store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c550e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zarr_load_waveform(store):\n",
    "    lazy = zarr.load(store)\n",
    "    \n",
    "    info = lazy['info'][0]\n",
    "\n",
    "    if info['fmt'] == 'v1':\n",
    "        ts   = lazy['ts']\n",
    "        data = lazy['data']\n",
    "        df = pd.concat([pd.DataFrame(ts),\n",
    "                        pd.DataFrame(data)], axis=1, ignore_index=True)\n",
    "        df.columns = ['ts', 'dt'] + info['cols']\n",
    "    \n",
    "        return df\n",
    "    elif info['fmt'] == 'v2':\n",
    "        data = lazy['data_v2']\n",
    "        df = pd.DataFrame(data)\n",
    "        df.columns = info['cols']\n",
    "\n",
    "        return df\n",
    "    else:\n",
    "        assert False, f\"load_waveform format {info['fmt']} unrecognized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532f278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_dir(save_dir, csn):\n",
    "    sdir = Path(save_dir) / Path('%03d' % (csn%1000))\n",
    "    return sdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612a4e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load PTSD records for CSN from DEVICE\n",
    "\n",
    "def load_record(ptsd_rec, csn, device, start=None, stop=None,\n",
    "                rate = None,\n",
    "                inst = None,\n",
    "                scale=None,\n",
    "                signal_contains = None,\n",
    "                data_dir = None,\n",
    "                tz_local = None,\n",
    "                add_dt = True,\n",
    "                csn_col = None,\n",
    "                load=True, verbose=False):\n",
    "    \"\"\"\n",
    "    load_record -- load PTSD records for CSN from DEVICE\n",
    "\n",
    "    Args:\n",
    "     - ptsd_rec -- ptsd_record dataframe\n",
    "     - csn\n",
    "     - device\n",
    "     - start\n",
    "     - stop\n",
    "     - *scale - timescale: 1 for sec, 1000 for ms.\n",
    "     - *data_dir\n",
    "    \"\"\"\n",
    "    if csn_col is None:\n",
    "        if 'pat_enc_csn_sid' in ptsd_rec.columns:\n",
    "            csn_col = 'pat_enc_csn_sid'\n",
    "        elif 'pat_enc_csn_id' in ptsd_rec.columns:\n",
    "            csn_col = 'pat_enc_csn_id'\n",
    "        else:\n",
    "            assert False, 'unable to find CSN col in ptsd_rec'\n",
    "\n",
    "    if data_dir is None:\n",
    "        p_root = Path(f\"/projects/ACCM-PMAP/data\")\n",
    "    else:\n",
    "        p_root = Path(data_dir)\n",
    "\n",
    "    if tz_local is None:\n",
    "        # tz_local = tz.gettz('America/East_Baltimore')\n",
    "        tz_local = tz.gettz('America/New_York')\n",
    "\n",
    "    if scale is None:\n",
    "        if device.endswith('VITAL') or device.endswith('WAVE'):\n",
    "            scale = 1000.0\n",
    "            subdir = 'vitals-sb'\n",
    "        else:\n",
    "            scale = 1.0\n",
    "            subdir = 'vitals-tsdb'\n",
    "\n",
    "    m = pd.Series(data=True, index=ptsd_rec.index)\n",
    "\n",
    "    m = m & (ptsd_rec[csn_col] == csn)\n",
    "    m = m & (ptsd_rec.device == device)\n",
    "\n",
    "    if start is not None:\n",
    "        m = m & (ptsd_rec.end_time > start)\n",
    "    if stop is not None:\n",
    "        m = m & (ptsd_rec.start_time < stop)\n",
    "    if rate is not None:\n",
    "        m = m & (ptsd_rec.rate == rate)\n",
    "    if inst is not None:\n",
    "        m = m & (ptsd_rec.inst_id == inst)\n",
    "\n",
    "    recs = ptsd_rec[m].sort_values('start_time')\n",
    "    \n",
    "    dfs = []\n",
    "    last_ts = None\n",
    "    for i in recs.index:\n",
    "        filename = recs.loc[i, 'filename']\n",
    "        fmt      = recs.loc[i, 'fmt']\n",
    "        rec_dt   = recs.loc[i, 'record_date']\n",
    "        rec_ts0  = pd.to_datetime(rec_dt).replace(tzinfo=tz_local).timestamp()\n",
    "        if fmt == 'zarr': fmt = 'zip'\n",
    "\n",
    "        p_file = p_root / subdir / f'{csn%1000:03}' / f'{filename}.{fmt}'\n",
    "\n",
    "        if verbose:\n",
    "            print(f'{device} {filename}.{fmt}: {p_file.exists()}')\n",
    "\n",
    "        if load:\n",
    "            if fmt == 'feather':\n",
    "                sub_df = pd.read_feather(p_file)\n",
    "            elif fmt == 'zip':\n",
    "                sub_df = zarr_load_waveform(str(p_file))\n",
    "            else: assert False, f\"fmt {fmt} unrecorgnized\"\n",
    "\n",
    "            if signal_contains is not None:\n",
    "                sigs = []\n",
    "                for sig in sub_df.columns:\n",
    "                    if signal_contains in sig:\n",
    "                        sigs.append(sig)\n",
    "                    elif sig == 'dts':\n",
    "                        sigs.append(sig)\n",
    "                sub_df = sub_df[sigs]\n",
    "\n",
    "            sub_df.dts = sub_df.dts/scale + rec_ts0\n",
    "            sub_df = sub_df.rename(columns={'dts': 'ts'})\n",
    "            sub_df['frame'] = len(dfs)\n",
    "\n",
    "            if last_ts is not None and sub_df.loc[0, 'ts'] - last_ts > 15:\n",
    "                print('insert gap')\n",
    "                dfs.append( pd.DataFrame({'ts': [last_ts + 1]}) )\n",
    "\n",
    "            dfs.append(sub_df)\n",
    "\n",
    "            last_ts = sub_df.loc[sub_df.shape[0]-1, 'ts']\n",
    "\n",
    "    if len(dfs) == 0:\n",
    "        return None\n",
    "\n",
    "    df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "    if add_dt:\n",
    "        if 'dt' in df:\n",
    "            df = df.rename(columns={'dt': 'orig_dt'})\n",
    "        df['dt'] = to_dt(df.ts)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb87ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to datetime\n",
    "\n",
    "def to_dt(ts):\n",
    "    \"\"\"\n",
    "    to_dt -- convert single/series of timestamps (Epoch times) to datetime\n",
    "    \n",
    "    Args\n",
    "     - ts -- timestamp (unix Epoch). SECONDS since 1970-1-1 00:00\n",
    "             can be scalar (single float/int), or pd.Series of float/int\n",
    "\n",
    "    Returns\n",
    "     - tz-naive datetime, in local timezone\n",
    "    \"\"\"\n",
    "    tz_local = tz.gettz('America/New_York')\n",
    "\n",
    "    if type(ts) is pd.Series:\n",
    "        # convert ts to datetime, with UTC timezone\n",
    "        t1 = pd.to_datetime(ts, unit='s', utc=True) # datetime, tz=UTC\n",
    "        # convert timezone from UTC to local\n",
    "        t2 = t1.dt.tz_convert(tz_local) # tz=local\n",
    "        # drop timezone\n",
    "        t3 = t2.dt.tz_localize(None)\n",
    "    else:\n",
    "        t1 = pd.to_datetime(ts, unit='s', utc=True) # to datetime, tz=UTC\n",
    "        t2 = t1.tz_convert(tz_local)                # tz=local\n",
    "        t3 = t2.tz_localize(None)                   # tz=None, aka niave\n",
    "\n",
    "    return t3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
