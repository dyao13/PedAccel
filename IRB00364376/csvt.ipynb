{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c660959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================== #\n",
    "# util/csvt -- save/load CSV files with pickled datatypes\n",
    "#\n",
    "# History\n",
    "#  - 10/7/2022 created, jpb\n",
    "# ===================================================================== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf41d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85280d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save CSV file, with pickled type info\n",
    "\n",
    "def save_csv_dtype(df, fp_csv, fp_dtype=None, dtype_only=False):\n",
    "    \"\"\"\n",
    "    Save CSV file with pickled type info\n",
    "\n",
    "    Args:\n",
    "     - df          -- pandas dataframe to save\n",
    "     - fp_csv      -- path to save CSV data\n",
    "     - fp_dtype    -- path to save pickled dtypes\n",
    "                      (default = CSV stem + '-dtypes.pkl')\n",
    "     - *dtype_only -- save just pickled dtypes (default = False)\n",
    "    \"\"\"\n",
    "    if not dtype_only:\n",
    "        df.to_csv(fp_csv, index=False)\n",
    "\n",
    "    if fp_dtype is None:\n",
    "        suffix   = ''.join(Path(fp_csv).suffixes)\n",
    "        fp_dtype = str(fp_csv).removesuffix(suffix) + '-dtypes.pkl'\n",
    "\n",
    "    df.dtypes.to_pickle(fp_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c477f06c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13024\\1105621481.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msave_csv_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr\"C:\\Users\\alacy5\\Documents\\DT6\\test\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "save_csv_dtype(df, r\"C:\\Users\\alacy5\\Documents\\DT6\\test\", fp_dtype=None, dtype_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4255f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation function for load_csv_type: fixes cat and date types\n",
    "\n",
    "def _clean_rdf(rdf, dtype, clean_cat, clean_date, verbose):\n",
    "    for col in clean_cat:\n",
    "        if verbose: print(f' - clean cat : {col}')\n",
    "        v_str = [ _.replace(\"(\",\"\").replace(\"]\", \"\").split(\", \")\n",
    "                  for _ in rdf[col] ]\n",
    "        v_int = [ pd.Interval(float(i), float(j)) for i, j in v_str]\n",
    "\n",
    "        rdf[col] = pd.Series(v_int).astype(dtype[col])\n",
    "\n",
    "    for col in clean_date:\n",
    "        if verbose: print(f' - clean date: {col}')\n",
    "        rdf[col] = rdf[col].astype(dtype[col])\n",
    "\n",
    "    return rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bea439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemenation class for load_csv_type: iterates over file\n",
    "\n",
    "class LCDIter:\n",
    "    def __init__(self, df_iter, dtype, clean_cat, clean_date, verbose):\n",
    "        self.df_iter    = df_iter\n",
    "        self.dtype      = dtype\n",
    "        self.clean_cat  = clean_cat\n",
    "        self.clean_date = clean_date\n",
    "        self.verbose    = verbose\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        rdf = self.df_iter.__next__()\n",
    "        return _clean_rdf(rdf, self.dtype, self.clean_cat, self.clean_date,\n",
    "                          self.verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabe1b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file, using pickled type info\n",
    "\n",
    "def load_csv_dtype(\n",
    "        fp_csv,\n",
    "        fp_dtype=None,\n",
    "        chunksize=None,\n",
    "        low_memory=True,\n",
    "        warn=True,\n",
    "        verbose = False):\n",
    "    \"\"\"\n",
    "    load CSV file, using pickled type info (from save_csv_types).\n",
    "\n",
    "    Args\n",
    "     - fp_csv      -- filepath to CSV file\n",
    "     - *fp_dtype   -- filepath to dtype file.  Defaults to stem of CSV\n",
    "                      file with \"-dtypes.pkl\" appended.\n",
    "     - *chunksize  -- Iterate over file in chunksize chunks. Default=None\n",
    "                      indicates load entire file. \n",
    "     - *low_memory -- passed to read_csv.  Honestly may not be necessary\n",
    "                      since the whole idea is to use the correct types\n",
    "                      from the dtypes.pkl file instead of inferring them.\n",
    "     - *warn       -- Print warnings.  Default = False\n",
    "     - *verbose    -- Be verbose.  Default = False\n",
    "\n",
    "    Returns:\n",
    "     Dataframe, or Dataframe iterator if chunksize set.\n",
    "    \"\"\"\n",
    "    \n",
    "    if fp_dtype is None:\n",
    "        suffix   = ''.join(Path(fp_csv).suffixes)\n",
    "        fp_dtype = str(fp_csv).removesuffix(suffix) + '-dtypes.pkl'\n",
    "        \n",
    "        # short circuit to read_csv\n",
    "        if not Path(fp_dtype).exists():\n",
    "            if warn:\n",
    "                print(f'load_csv_dtype: unable to infer dtypes filename ({fp_dtype})')\n",
    "            return pd.read_csv(fp_csv,\n",
    "                               low_memory = low_memory,\n",
    "                               chunksize  = chunksize)\n",
    "    \n",
    "    dtype = pd.read_pickle(fp_dtype)\n",
    "\n",
    "\n",
    "    #\n",
    "    # Find categorical and date types.  These require additional processing\n",
    "    # after the initial read_csv\n",
    "    #\n",
    "    clean_cat  = []\n",
    "    clean_date = []\n",
    "    dtype_read = dtype.copy()\n",
    "    for index, value in dtype_read.items():\n",
    "        if (type(value) == pd.CategoricalDtype and\n",
    "            type(value.categories[0]) == pd.Interval):\n",
    "            dtype_read[index] = 'category'\n",
    "            clean_cat.append(index)\n",
    "        elif str(value) == 'datetime64[ns]':\n",
    "            dtype_read[index] = 'object'\n",
    "            clean_date.append(index)\n",
    "\n",
    "    if chunksize is not None:\n",
    "        try:\n",
    "            df_iter = pd.read_csv(fp_csv, dtype=dtype_read.to_dict(),\n",
    "                                  low_memory = low_memory,\n",
    "                                  chunksize = chunksize)\n",
    "        except:\n",
    "            print(f'ERROR: during load_csv_dtype({fp_csv}, ...)',\n",
    "                  file=sys.stderr)\n",
    "            print(f'     : exception in pd.read_csv(w/chunksize)',\n",
    "                  file=sys.stderr)\n",
    "            raise\n",
    "        return LCDIter(df_iter, dtype, clean_cat, clean_date, verbose)\n",
    "    else:\n",
    "        try:\n",
    "            rdf = pd.read_csv(fp_csv, dtype=dtype_read.to_dict(),\n",
    "                              low_memory = low_memory)\n",
    "        except:\n",
    "            print(f'ERROR: during load_csv_dtype({fp_csv}, ...)',\n",
    "                  file=sys.stderr)\n",
    "            print(f'     : exception in pd.read_csv',\n",
    "                  file=sys.stderr)\n",
    "            raise\n",
    "\n",
    "        return _clean_rdf(rdf, dtype, clean_cat, clean_date, verbose)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
